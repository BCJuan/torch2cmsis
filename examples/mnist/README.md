# MNIST Example

In this folder you will find a full example on how to use the CMSIS Converter to obtain automatically the quantized weights of the network, as well as the parameters necessary to call CMSIS functions.

In this case, however, the automatic code generator is not used and we still need to write our CMSIS network manually.

You can run the full example by `python main.py`

## Training the network

In the file `mnist.py`, you will find everything from the PyTorch side.

1. Data loading
2. Network definition
3. Training

is of utmost importancy that in your network there is a function called `get_shape`, that returns the shape of the feature map just before going to fully connected layers. For example, in the network defined this function is:

```
    def get_shape(self):
        sample = torch.randn(size=(self.batch_size, *self.input_shape))
        out = self.conv1(sample)
        out = self.pool1(out)
        out = self.relu1(out)
        out = self.conv2(out)
        out = self.pool2(out)
        out = self.relu2(out)       
        return out.shape[1:]
```

This is necessary because the `CMSISConverter` needs this shape for doing a proper conversion of the fully connected layer weights, as described in [the CMSIS conversion tutorial](https://developer.arm.com/solutions/machine-learning-on-arm/developer-material/how-to-guides/converting-a-neural-network-for-arm-cortex-m-with-cmsis-nn/single-page).

Then in our `main.py`, we just train our network and evaluate it:

```
    datasets = config["dataset"]()
    dataloaders =  {
            i: DataLoader(
                sett,
                batch_size=config["batch_size"],
                shuffle=True,
                num_workers=4
                )
            for i, sett in zip(["train", "val", "test"], datasets)
        }
    cnn = SampleCNN(shape=config["shape"], batch_size = config["batch_size"])
    trainer = SimpleTrainer(
        datasets=datasets,
        dataloaders=dataloaders
    )
    cnn = trainer.train(cnn, config, config.get("name"))
    accuracy_test = trainer.evaluate(cnn)
```

## Converting the network

### Instantiating CMSISConverter

The first thing to convert the previous network, which is the object `cnn` in the code, is to instantiate the CMSISConverter:

```
cm_converter = CMSISConverter(root="cfiles", model=cnn, weight_file_name="weights.h", parameter_file_name="parameters.h",
                                weight_bits=8, compilation=...))
```

Each of the parameters are:

+ root: the folder where the C code is 
+ model: PyTorch model
+ weight_file_name: header file for weights
+ parameter_file_name: header file for parameters
+ weight bits: how may bits is quantized your network, 8 or 16.
+ compilation: compilation string to compile the program online

The compilation line given in this case is:

```
'gcc -g -I../../../CMSIS_5/CMSIS/Core/Include \
            -I../../../CMSIS_5/CMSIS/DSP/Include \
            -I../../../CMSIS_5/CMSIS/NN/Include \
            -D__ARM_ARCH_8M_BASE__ \
            ../../../CMSIS_5/CMSIS/NN/Source/*/*.c \
            ../../../CMSIS_5/CMSIS/DSP/Source/StatisticsFunctions/arm_max_q7.c \
            main.c -o main'
```
### Collecting statistics for quantization and convert model

The procedure to e able to quantize the model is the following (see [ARM CMSIS Quantizer for Caffe](https://github.com/ARM-software/ML-examples/blob/master/cmsisnn-cifar10/nn_quantizer.py) ):

+ Collect statistics for input, output, weight and bias
+ Extract all parameters for CMSIS
+ Refine weight, bias and activation Q.Q. format heuristically
+ Convert weights and save files

If you want, you only need to make a call to `cm_converter.convert_model(<dataloader>)`:

```
cm_converter.convert_model(dataloaders["val"])
```

However, this function calls all the sequence of steps detailed previously:

```
    def convert_model(self, loader):
        self.generate_intermediate_values(loader) # statistics
        self.save_params_model() # saving the params
        self.refine_model_weights(loader) # refining weights Q.Q
        self.refine_model_weights(loader, bias=True) # same for bias
        self.refine_activations(loader) # same for activation
        self.reassign_q_params_n_shifts() # checking graph connectivity to arrange Q.Q input and output match
        self.write_shifts_n_params() # write all the Q.Q params
        self.convert_weights() # convert and save weights
```

### Building your network

Currently, you should build by yourself your CMSIS network, as seen in `cfiles/main.c`, by using all the parameters and weights generated by the converted. For example, here we declare the weights of the first convolutional layer and then we have also the function call:

```
q7_t conv1_out[CONV1_OUT_CH*CONV1_OUT_DIM*CONV1_OUT_DIM];
q7_t conv1_w[CONV1_WT_SHAPE] = CONV1_WT;

...

arm_convolve_HWC_q7_basic(input, CONV1_IM_DIM, CONV1_IM_CH, conv1_w, CONV1_OUT_CH, CONV1_KER_DIM, CONV1_PADDING,
                        CONV1_STRIDE, conv1_b, CONV1_BIAS_LSHIFT, CONV1_OUT_RSHIFT, conv1_out, CONV1_OUT_DIM,
                        (q15_t *) conv_buffer, fc_buffer);
```


### Testing your network

If you want to test your network is important that you save the output of your last layer in the model as `y_out.raw`. You can see how, at `main.c`:

```
...
arm_fully_connected_q7_opt(fc1_out, fc2_w, FC2_DIM, FC2_OUT, FC2_BIAS_LSHIFT, FC2_OUT_RSHIFT, fc2_b,
                        fc2_out, (q15_t *) fc_buffer);
save("logs/fc2_out.raw", fc2_out, sizeof(fc2_out));

arm_softmax_q7(fc2_out, FC2_OUT, y_out);
save("logs/y_out.raw", y_out, sizeof(y_out));
```

Then, you can call the method `evaluate_cmsis` from `CMSISConverter`. As seen in `main.py`

```
    cm_converter.evaluate_cmsis(config.get("exec_path"), dataloaders['test'])
```

where the `exec_path` is the name of the execution file, in this case `main`.

